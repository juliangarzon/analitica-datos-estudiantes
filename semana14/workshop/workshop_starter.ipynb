{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cell-0",
   "metadata": {},
   "source": [
    "# Week 14 Workshop: ML Models - Classification & Regression\n",
    "\n",
    "## Water Consumption Dataset\n",
    "\n",
    "### Objectives\n",
    "1. Build and compare 3+ machine learning models\n",
    "2. Create confusion matrix (classification) or residual analysis (regression)\n",
    "3. Calculate and visualize feature importance\n",
    "4. Document model selection rationale\n",
    "\n",
    "### Duration: 2-3 hours\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-1",
   "metadata": {},
   "source": [
    "## Setup\n",
    "\n",
    "Run this cell to load all necessary libraries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# scikit-learn imports\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "\n",
    "# Regression models\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "\n",
    "# Classification models\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "# Metrics\n",
    "from sklearn.metrics import (\n",
    "    # Regression metrics\n",
    "    mean_squared_error, mean_absolute_error, r2_score,\n",
    "    # Classification metrics\n",
    "    accuracy_score, precision_score, recall_score, f1_score,\n",
    "    classification_report, confusion_matrix\n",
    ")\n",
    "\n",
    "# Visualization settings\n",
    "plt.style.use('seaborn-v0_8-whitegrid')\n",
    "sns.set_palette('husl')\n",
    "\n",
    "# Suppress warnings\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "print(\"Libraries loaded successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Water Consumption dataset from datos.gov.co\n",
    "url = \"https://www.datos.gov.co/resource/k9gy-47jj.csv?$limit=10000\"\n",
    "\n",
    "df = pd.read_csv(url)\n",
    "\n",
    "print(f\"Dataset loaded successfully!\")\n",
    "print(f\"Shape: {df.shape[0]} rows x {df.shape[1]} columns\")\n",
    "print(f\"\\nColumns:\")\n",
    "print(df.columns.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preview the data\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check data types\n",
    "print(\"Data Types:\")\n",
    "print(df.dtypes)\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"\\nMissing Values:\")\n",
    "print(df.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Numeric summary\n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-7",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# Part 1: Data Preparation\n",
    "\n",
    "Prepare your data for modeling.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-8",
   "metadata": {},
   "source": [
    "## 1.1 Identify Columns\n",
    "\n",
    "Identify which columns are numeric and which are categorical."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Identify column types\n",
    "numeric_cols = df.select_dtypes(include=[np.number]).columns.tolist()\n",
    "categorical_cols = df.select_dtypes(include=['object']).columns.tolist()\n",
    "\n",
    "print(\"Numeric columns:\")\n",
    "for col in numeric_cols:\n",
    "    print(f\"  - {col}\")\n",
    "\n",
    "print(f\"\\nCategorical columns:\")\n",
    "for col in categorical_cols:\n",
    "    print(f\"  - {col}: {df[col].nunique()} unique values\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-10",
   "metadata": {},
   "source": [
    "## 1.2 Select Target Variable\n",
    "\n",
    "Choose your target variable:\n",
    "- For **regression**: Choose a continuous numeric column (e.g., consumption amount)\n",
    "- For **classification**: Choose a categorical column or create categories from a numeric column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-11",
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR CODE HERE: Select the target column\n",
    "# Look for consumption-related columns\n",
    "\n",
    "# Find potential target columns\n",
    "consumption_candidates = [col for col in numeric_cols if any(x in col.lower() for x in ['consumo', 'consumption', 'valor', 'cantidad', 'total'])]\n",
    "print(f\"Potential target columns: {consumption_candidates}\")\n",
    "\n",
    "# Select target (UPDATE this based on your dataset)\n",
    "target_col = ___  # e.g., consumption_candidates[0] or a specific column name\n",
    "\n",
    "print(f\"\\nSelected target: {target_col}\")\n",
    "print(df[target_col].describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-12",
   "metadata": {},
   "source": [
    "## 1.3 Handle Missing Values\n",
    "\n",
    "Check for and handle missing values in your data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-13",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check missing values\n",
    "print(\"Missing values per column:\")\n",
    "missing = df.isnull().sum()\n",
    "print(missing[missing > 0])\n",
    "\n",
    "# YOUR CODE HERE: Handle missing values\n",
    "# Option 1: Drop rows with missing values\n",
    "# df_clean = df.dropna()\n",
    "\n",
    "# Option 2: Fill with mean/median (for numeric)\n",
    "# df['column'] = df['column'].fillna(df['column'].mean())\n",
    "\n",
    "# Option 3: Fill with mode (for categorical)\n",
    "# df['column'] = df['column'].fillna(df['column'].mode()[0])\n",
    "\n",
    "df_clean = ___\n",
    "\n",
    "print(f\"\\nRows before cleaning: {len(df)}\")\n",
    "print(f\"Rows after cleaning: {len(df_clean)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-14",
   "metadata": {},
   "source": [
    "## 1.4 Select Features\n",
    "\n",
    "Choose which columns to use as features (X)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-15",
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR CODE HERE: Select feature columns\n",
    "# Remove target column and any ID/code columns from features\n",
    "\n",
    "# Get numeric columns (excluding target)\n",
    "feature_cols = [col for col in numeric_cols if col != target_col]\n",
    "\n",
    "# Remove ID-like columns\n",
    "id_patterns = ['id', 'codigo', 'code', 'key']\n",
    "feature_cols = [col for col in feature_cols if not any(p in col.lower() for p in id_patterns)]\n",
    "\n",
    "print(f\"Selected features: {feature_cols}\")\n",
    "print(f\"Number of features: {len(feature_cols)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-16",
   "metadata": {},
   "source": [
    "## 1.5 Prepare X and y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-17",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare features (X) and target (y)\n",
    "X = df_clean[feature_cols]\n",
    "y = df_clean[target_col]\n",
    "\n",
    "print(f\"X shape: {X.shape}\")\n",
    "print(f\"y shape: {y.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-18",
   "metadata": {},
   "source": [
    "## 1.6 Train-Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-19",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split data: 80% training, 20% testing\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y,\n",
    "    test_size=0.2,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "print(f\"Training set: {X_train.shape[0]} samples\")\n",
    "print(f\"Test set: {X_test.shape[0]} samples\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-20",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# Part 2: Build and Compare 3+ Models\n",
    "\n",
    "Implement at least 3 different models and compare their performance.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-21",
   "metadata": {},
   "source": [
    "## Model 1: Linear Regression\n",
    "\n",
    "Start with the simplest model as a baseline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-22",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model 1: Linear Regression\n",
    "# YOUR CODE HERE\n",
    "\n",
    "# Step 1: Create the model\n",
    "model_1 = ___\n",
    "\n",
    "# Step 2: Train the model\n",
    "___\n",
    "\n",
    "# Step 3: Make predictions\n",
    "y_pred_1 = ___\n",
    "\n",
    "# Step 4: Calculate metrics\n",
    "rmse_1 = np.sqrt(mean_squared_error(y_test, y_pred_1))\n",
    "mae_1 = mean_absolute_error(y_test, y_pred_1)\n",
    "r2_1 = r2_score(y_test, y_pred_1)\n",
    "\n",
    "print(\"=== MODEL 1: LINEAR REGRESSION ===\")\n",
    "print(f\"RMSE: {rmse_1:.4f}\")\n",
    "print(f\"MAE: {mae_1:.4f}\")\n",
    "print(f\"R-squared: {r2_1:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-23",
   "metadata": {},
   "source": [
    "## Model 2: Decision Tree\n",
    "\n",
    "A tree-based model that can capture non-linear patterns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-24",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model 2: Decision Tree\n",
    "# YOUR CODE HERE\n",
    "\n",
    "# Step 1: Create the model (use max_depth to prevent overfitting)\n",
    "model_2 = ___\n",
    "\n",
    "# Step 2: Train the model\n",
    "___\n",
    "\n",
    "# Step 3: Make predictions\n",
    "y_pred_2 = ___\n",
    "\n",
    "# Step 4: Calculate metrics\n",
    "rmse_2 = np.sqrt(mean_squared_error(y_test, y_pred_2))\n",
    "mae_2 = mean_absolute_error(y_test, y_pred_2)\n",
    "r2_2 = r2_score(y_test, y_pred_2)\n",
    "\n",
    "print(\"=== MODEL 2: DECISION TREE ===\")\n",
    "print(f\"RMSE: {rmse_2:.4f}\")\n",
    "print(f\"MAE: {mae_2:.4f}\")\n",
    "print(f\"R-squared: {r2_2:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-25",
   "metadata": {},
   "source": [
    "## Model 3: Random Forest\n",
    "\n",
    "An ensemble of decision trees for better accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-26",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model 3: Random Forest\n",
    "# YOUR CODE HERE\n",
    "\n",
    "# Step 1: Create the model\n",
    "model_3 = ___\n",
    "\n",
    "# Step 2: Train the model\n",
    "___\n",
    "\n",
    "# Step 3: Make predictions\n",
    "y_pred_3 = ___\n",
    "\n",
    "# Step 4: Calculate metrics\n",
    "rmse_3 = np.sqrt(mean_squared_error(y_test, y_pred_3))\n",
    "mae_3 = mean_absolute_error(y_test, y_pred_3)\n",
    "r2_3 = r2_score(y_test, y_pred_3)\n",
    "\n",
    "print(\"=== MODEL 3: RANDOM FOREST ===\")\n",
    "print(f\"RMSE: {rmse_3:.4f}\")\n",
    "print(f\"MAE: {mae_3:.4f}\")\n",
    "print(f\"R-squared: {r2_3:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-27",
   "metadata": {},
   "source": [
    "## (Optional) Model 4: Gradient Boosting or KNN\n",
    "\n",
    "Add a 4th model for extra credit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-28",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model 4: (Optional) Gradient Boosting or KNN\n",
    "# YOUR CODE HERE\n",
    "\n",
    "# model_4 = GradientBoostingRegressor(n_estimators=100, max_depth=3, random_state=42)\n",
    "# OR\n",
    "# model_4 = KNeighborsRegressor(n_neighbors=5)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-29",
   "metadata": {},
   "source": [
    "## Model Comparison Table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-30",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create comparison table\n",
    "# YOUR CODE HERE: Add all models you trained\n",
    "\n",
    "comparison = pd.DataFrame({\n",
    "    'Model': ['Linear Regression', 'Decision Tree', 'Random Forest'],\n",
    "    'RMSE': [rmse_1, rmse_2, rmse_3],\n",
    "    'MAE': [mae_1, mae_2, mae_3],\n",
    "    'R-squared': [r2_1, r2_2, r2_3]\n",
    "})\n",
    "\n",
    "print(\"=== MODEL COMPARISON ===\")\n",
    "print(comparison.to_string(index=False))\n",
    "\n",
    "# Identify best model\n",
    "best_idx = comparison['R-squared'].idxmax()\n",
    "best_model_name = comparison.loc[best_idx, 'Model']\n",
    "print(f\"\\nBest Model (highest R-squared): {best_model_name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-31",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize model comparison\n",
    "fig, axes = plt.subplots(1, 3, figsize=(14, 5))\n",
    "\n",
    "models = comparison['Model'].tolist()\n",
    "colors = ['steelblue', 'coral', 'seagreen']\n",
    "\n",
    "# RMSE comparison\n",
    "axes[0].bar(models, comparison['RMSE'], color=colors)\n",
    "axes[0].set_ylabel('RMSE (lower is better)', fontsize=11)\n",
    "axes[0].set_title('RMSE Comparison', fontsize=13)\n",
    "axes[0].tick_params(axis='x', rotation=20)\n",
    "\n",
    "# MAE comparison\n",
    "axes[1].bar(models, comparison['MAE'], color=colors)\n",
    "axes[1].set_ylabel('MAE (lower is better)', fontsize=11)\n",
    "axes[1].set_title('MAE Comparison', fontsize=13)\n",
    "axes[1].tick_params(axis='x', rotation=20)\n",
    "\n",
    "# R-squared comparison\n",
    "axes[2].bar(models, comparison['R-squared'], color=colors)\n",
    "axes[2].set_ylabel('R-squared (higher is better)', fontsize=11)\n",
    "axes[2].set_title('R-squared Comparison', fontsize=13)\n",
    "axes[2].tick_params(axis='x', rotation=20)\n",
    "axes[2].set_ylim(0, 1)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-32",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# Part 3: Confusion Matrix / Residual Analysis\n",
    "\n",
    "**For Regression:** Create residual analysis.\n",
    "\n",
    "**For Classification:** Create confusion matrix.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-33",
   "metadata": {},
   "source": [
    "## Option A: Residual Analysis (for Regression)\n",
    "\n",
    "Analyze the residuals (errors) of your best model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-34",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Residual Analysis for Best Model (Random Forest)\n",
    "# YOUR CODE HERE: Use the predictions from your best model\n",
    "\n",
    "# Calculate residuals\n",
    "residuals = y_test - y_pred_3  # Update y_pred_3 to your best model's predictions\n",
    "\n",
    "print(\"Residual Statistics:\")\n",
    "print(f\"Mean: {residuals.mean():.4f} (should be close to 0)\")\n",
    "print(f\"Std: {residuals.std():.4f}\")\n",
    "print(f\"Min: {residuals.min():.4f}\")\n",
    "print(f\"Max: {residuals.max():.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-35",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize residuals\n",
    "fig, axes = plt.subplots(1, 3, figsize=(15, 5))\n",
    "\n",
    "# 1. Residual distribution (should be normal)\n",
    "axes[0].hist(residuals, bins=30, color='steelblue', edgecolor='white', alpha=0.7)\n",
    "axes[0].axvline(0, color='red', linestyle='--', linewidth=2)\n",
    "axes[0].set_xlabel('Residual', fontsize=11)\n",
    "axes[0].set_ylabel('Frequency', fontsize=11)\n",
    "axes[0].set_title('Residual Distribution', fontsize=13)\n",
    "\n",
    "# 2. Residuals vs Predicted (should show no pattern)\n",
    "axes[1].scatter(y_pred_3, residuals, alpha=0.5, color='steelblue')\n",
    "axes[1].axhline(0, color='red', linestyle='--', linewidth=2)\n",
    "axes[1].set_xlabel('Predicted Values', fontsize=11)\n",
    "axes[1].set_ylabel('Residuals', fontsize=11)\n",
    "axes[1].set_title('Residuals vs Predicted', fontsize=13)\n",
    "\n",
    "# 3. Actual vs Predicted\n",
    "axes[2].scatter(y_test, y_pred_3, alpha=0.5, color='steelblue')\n",
    "axes[2].plot([y_test.min(), y_test.max()], [y_test.min(), y_test.max()], 'r--', linewidth=2)\n",
    "axes[2].set_xlabel('Actual Values', fontsize=11)\n",
    "axes[2].set_ylabel('Predicted Values', fontsize=11)\n",
    "axes[2].set_title('Actual vs Predicted', fontsize=13)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-36",
   "metadata": {},
   "source": [
    "### Residual Interpretation\n",
    "\n",
    "**Write your interpretation below:**\n",
    "\n",
    "*What do the residual plots tell you about your model's performance?*\n",
    "\n",
    "- Is the residual distribution approximately normal?\n",
    "- Are there any patterns in the residuals vs predicted plot?\n",
    "- Are there any obvious outliers?\n",
    "\n",
    "*YOUR INTERPRETATION HERE*\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-37",
   "metadata": {},
   "source": [
    "## Option B: Confusion Matrix (for Classification)\n",
    "\n",
    "If you converted this to a classification problem, create a confusion matrix.\n",
    "\n",
    "**Example:** Convert consumption to categories (Low, Medium, High)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-38",
   "metadata": {},
   "outputs": [],
   "source": [
    "# OPTIONAL: Convert to classification problem\n",
    "# Create consumption categories based on quartiles\n",
    "\n",
    "# def categorize_consumption(value, thresholds):\n",
    "#     if value < thresholds[0]:\n",
    "#         return 'Low'\n",
    "#     elif value < thresholds[1]:\n",
    "#         return 'Medium'\n",
    "#     else:\n",
    "#         return 'High'\n",
    "\n",
    "# thresholds = [y.quantile(0.33), y.quantile(0.66)]\n",
    "# y_cat = y.apply(lambda x: categorize_consumption(x, thresholds))\n",
    "\n",
    "# Then train classification models and create confusion matrix...\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-39",
   "metadata": {},
   "outputs": [],
   "source": [
    "# OPTIONAL: Confusion Matrix Visualization\n",
    "# YOUR CODE HERE (if doing classification)\n",
    "\n",
    "# cm = confusion_matrix(y_test_cat, y_pred_cat)\n",
    "# \n",
    "# plt.figure(figsize=(8, 6))\n",
    "# sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',\n",
    "#             xticklabels=['Low', 'Medium', 'High'],\n",
    "#             yticklabels=['Low', 'Medium', 'High'])\n",
    "# plt.xlabel('Predicted', fontsize=12)\n",
    "# plt.ylabel('Actual', fontsize=12)\n",
    "# plt.title('Confusion Matrix', fontsize=14)\n",
    "# plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-40",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# Part 4: Feature Importance\n",
    "\n",
    "Calculate and visualize which features are most important for predictions.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-41",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature Importance from Random Forest (or your best tree-based model)\n",
    "# YOUR CODE HERE: Use model_3 (Random Forest) or model_2 (Decision Tree)\n",
    "\n",
    "# Get feature importances\n",
    "importances = ___  # e.g., model_3.feature_importances_\n",
    "\n",
    "# Create DataFrame\n",
    "feature_importance = pd.DataFrame({\n",
    "    'feature': feature_cols,\n",
    "    'importance': importances\n",
    "}).sort_values('importance', ascending=False)\n",
    "\n",
    "print(\"Feature Importance Ranking:\")\n",
    "print(feature_importance.to_string(index=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-42",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize Feature Importance\n",
    "fig, ax = plt.subplots(figsize=(10, 6))\n",
    "\n",
    "# Horizontal bar chart\n",
    "bars = ax.barh(feature_importance['feature'], feature_importance['importance'], \n",
    "               color='steelblue', edgecolor='white')\n",
    "\n",
    "ax.set_xlabel('Importance', fontsize=12)\n",
    "ax.set_ylabel('Feature', fontsize=12)\n",
    "ax.set_title('Feature Importance (Random Forest)', fontsize=14)\n",
    "ax.invert_yaxis()  # Highest importance at top\n",
    "\n",
    "# Add value labels\n",
    "for bar, imp in zip(bars, feature_importance['importance']):\n",
    "    ax.text(bar.get_width() + 0.01, bar.get_y() + bar.get_height()/2,\n",
    "            f'{imp:.3f}', va='center', fontsize=10)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-43",
   "metadata": {},
   "source": [
    "### Feature Importance Interpretation\n",
    "\n",
    "**Write your interpretation below:**\n",
    "\n",
    "*Which features are most important for predicting water consumption?*\n",
    "\n",
    "*Do these results make sense from a domain perspective?*\n",
    "\n",
    "*YOUR INTERPRETATION HERE*\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-44",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# Part 5: Model Selection Rationale\n",
    "\n",
    "Document your analysis and model recommendation.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-45",
   "metadata": {},
   "source": [
    "## Summary of Results\n",
    "\n",
    "**Complete the table below with your results:**\n",
    "\n",
    "| Model | RMSE | MAE | R-squared | Notes |\n",
    "|-------|------|-----|-----------|-------|\n",
    "| Linear Regression | ___ | ___ | ___ | Baseline model |\n",
    "| Decision Tree | ___ | ___ | ___ | ___ |\n",
    "| Random Forest | ___ | ___ | ___ | ___ |\n",
    "| (Optional 4th) | ___ | ___ | ___ | ___ |\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-46",
   "metadata": {},
   "source": [
    "## Model Selection Rationale\n",
    "\n",
    "**Write your 1-page analysis below. Address each section:**\n",
    "\n",
    "### 1. Models Tested and Performance\n",
    "\n",
    "*Summarize what models you tested and how they performed.*\n",
    "\n",
    "*YOUR ANALYSIS HERE*\n",
    "\n",
    "### 2. Recommended Model\n",
    "\n",
    "*Which model do you recommend and WHY?*\n",
    "\n",
    "*Consider: accuracy, interpretability, speed, risk of overfitting*\n",
    "\n",
    "*YOUR RECOMMENDATION HERE*\n",
    "\n",
    "### 3. Trade-offs\n",
    "\n",
    "*What are the trade-offs of your chosen model?*\n",
    "\n",
    "*For example: Random Forest is more accurate but less interpretable than Linear Regression*\n",
    "\n",
    "*YOUR ANALYSIS HERE*\n",
    "\n",
    "### 4. Future Improvements\n",
    "\n",
    "*What would you try next to improve performance?*\n",
    "\n",
    "*Ideas: more features, feature engineering, hyperparameter tuning, more data, etc.*\n",
    "\n",
    "*YOUR IDEAS HERE*\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-47",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Final Checklist\n",
    "\n",
    "Before submitting, verify:\n",
    "\n",
    "- [ ] All cells have been executed (Kernel > Restart & Run All)\n",
    "- [ ] Part 1: Data is properly prepared\n",
    "- [ ] Part 2: At least 3 models implemented and compared\n",
    "- [ ] Part 3: Confusion matrix or residual analysis completed\n",
    "- [ ] Part 4: Feature importance calculated and visualized\n",
    "- [ ] Part 5: Model selection rationale written\n",
    "\n",
    "---\n",
    "\n",
    "*Week 14 Workshop - Data Analytics Course - Universidad Cooperativa de Colombia*"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
